{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows = 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "# Creating the datasets\n",
    "house_data_train = pd.read_csv(\"train.csv\")\n",
    "house_data_test = pd.read_csv(\"test.csv\")\n",
    "# Target prices:\n",
    "y = house_data_train['SalePrice']\n",
    "house_data_train = house_data_train.drop(columns=['SalePrice'])\n",
    "house_data_train.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 912.6+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# Values and meanings from the first column, MSSubClass\n",
    "MSSubClass_dict = { \n",
    "        20:\t'1-STORY 1946 & NEWER ALL STYLES', \n",
    "        30:\t'1-STORY 1945 & OLDER', \n",
    "        40:\t'1-STORY W/FINISHED ATTIC ALL AGES',\n",
    "        45:\t'1-1/2 STORY - UNFINISHED ALL AGES', \n",
    "        50:\t'1-1/2 STORY FINISHED ALL AGES', \n",
    "        60:\t'2-STORY 1946 & NEWER', \n",
    "        70:\t'2-STORY 1945 & OLDER', \n",
    "        75:\t'2-1/2 STORY ALL AGES', \n",
    "        80:\t'SPLIT OR MULTI-LEVEL', \n",
    "        85:\t'SPLIT FOYER', \n",
    "        90:\t'DUPLEX - ALL STYLES AND AGES', \n",
    "       120:\t'1-STORY PUD (Planned Unit Development) - 1946 & NEWER', \n",
    "       150:\t'1-1/2 STORY PUD - ALL AGES', \n",
    "       160:\t'2-STORY PUD - 1946 & NEWER', \n",
    "       180:\t'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER', \n",
    "       190:\t'2 FAMILY CONVERSION - ALL STYLES AND AGES'}\n",
    "\n",
    "# Replacing numbers with column names\n",
    "house_data_train['MSSubClass'].replace(MSSubClass_dict, inplace=True)\n",
    "house_data_test['MSSubClass'].replace(MSSubClass_dict, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "categorical_columns = list(house_data_train.dtypes[house_data_train.dtypes == np.object].index)\n",
    "numerical_columns = list(house_data_train.dtypes[house_data_train.dtypes != np.object].index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# Numerical and categorical dataframes\n",
    "numerical_train = house_data_train[numerical_columns]\n",
    "numerical_test = house_data_test[numerical_columns]\n",
    "categorical_train = house_data_train[categorical_columns]\n",
    "categorical_test = house_data_test[categorical_columns]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# Meanings of the Condition1 and Condition2 column values\n",
    "cond = {\n",
    "    'Artery':\t'Adjacent to arterial street',\n",
    "    'Feedr':\t'Adjacent to feeder street',\t\n",
    "    'Norm':\t'Normal',\t\n",
    "    'RRNn':\t'Within 200 of North-South Railroad',\n",
    "    'RRAn':\t'Adjacent to North-South Railroad',\n",
    "    'PosN':\t'Near positive off-site feature--park, greenbelt, etc.',\n",
    "    'PosA':\t'Adjacent to postive off-site feature',\n",
    "    'RRNe':\t'Within 200 of East-West Railroad',\n",
    "    'RRAe':\t'Adjacent to East-West Railroad'\n",
    "}\n",
    "# Getting the full name of the conditions\n",
    "categorical_train['Condition1'].replace(cond, inplace=True)\n",
    "categorical_train['Condition2'].replace(cond, inplace=True)\n",
    "categorical_test['Condition1'].replace(cond, inplace=True)\n",
    "categorical_test['Condition2'].replace(cond, inplace=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pandas/core/generic.py:6610: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "def sum_1hots(df, column1, column2):\n",
    "    '''This function is for getting only one hot encoder for repeated \n",
    "    conditions in some columns in the dataset '''\n",
    "    c1 = pd.get_dummies(df[column1])\n",
    "    c2 = pd.get_dummies(df[column2])\n",
    "    # Sum both one hot encoders. Exploring this data, I found some 2's, that makes \n",
    "    # no sense, so, I replaced them with 1's\n",
    "    c1c2 = c1.add(c2, fill_value=0).replace(2,1)\n",
    "    df = df.drop(columns=[column1, column2])\n",
    "    return df, c1c2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "categorical_train, cond_col_train = sum_1hots(categorical_train, 'Condition1', 'Condition2')\n",
    "categorical_train, ext_col_train = sum_1hots(categorical_train, 'Exterior1st', 'Exterior2nd')\n",
    "categorical_test, cond_col_test = sum_1hots(categorical_test, 'Condition1', 'Condition2')\n",
    "categorical_test, ext_col_test = sum_1hots(categorical_test, 'Exterior1st', 'Exterior2nd')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handling zero values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "categorical_train.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 40 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   MSSubClass     1460 non-null   object\n",
      " 1   MSZoning       1460 non-null   object\n",
      " 2   Street         1460 non-null   object\n",
      " 3   Alley          91 non-null     object\n",
      " 4   LotShape       1460 non-null   object\n",
      " 5   LandContour    1460 non-null   object\n",
      " 6   Utilities      1460 non-null   object\n",
      " 7   LotConfig      1460 non-null   object\n",
      " 8   LandSlope      1460 non-null   object\n",
      " 9   Neighborhood   1460 non-null   object\n",
      " 10  BldgType       1460 non-null   object\n",
      " 11  HouseStyle     1460 non-null   object\n",
      " 12  RoofStyle      1460 non-null   object\n",
      " 13  RoofMatl       1460 non-null   object\n",
      " 14  MasVnrType     1452 non-null   object\n",
      " 15  ExterQual      1460 non-null   object\n",
      " 16  ExterCond      1460 non-null   object\n",
      " 17  Foundation     1460 non-null   object\n",
      " 18  BsmtQual       1423 non-null   object\n",
      " 19  BsmtCond       1423 non-null   object\n",
      " 20  BsmtExposure   1422 non-null   object\n",
      " 21  BsmtFinType1   1423 non-null   object\n",
      " 22  BsmtFinType2   1422 non-null   object\n",
      " 23  Heating        1460 non-null   object\n",
      " 24  HeatingQC      1460 non-null   object\n",
      " 25  CentralAir     1460 non-null   object\n",
      " 26  Electrical     1459 non-null   object\n",
      " 27  KitchenQual    1460 non-null   object\n",
      " 28  Functional     1460 non-null   object\n",
      " 29  FireplaceQu    770 non-null    object\n",
      " 30  GarageType     1379 non-null   object\n",
      " 31  GarageFinish   1379 non-null   object\n",
      " 32  GarageQual     1379 non-null   object\n",
      " 33  GarageCond     1379 non-null   object\n",
      " 34  PavedDrive     1460 non-null   object\n",
      " 35  PoolQC         7 non-null      object\n",
      " 36  Fence          281 non-null    object\n",
      " 37  MiscFeature    54 non-null     object\n",
      " 38  SaleType       1460 non-null   object\n",
      " 39  SaleCondition  1460 non-null   object\n",
      "dtypes: object(40)\n",
      "memory usage: 456.4+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "# Replacing with a string the nan values. While exploring what kind of nan values we have in the data, \n",
    "# is ok to fill with a Not Aplicable condition. (no basement, no pool, etc)\n",
    "categorical_train.fillna('Not Aplicable', inplace=True)\n",
    "categorical_test.fillna('Not Aplicable', inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "# With the numerical columns, we only have one that is special, the \n",
    "# year when the garage was built, we fill with the average year\n",
    "avg_garage_year = numerical_train['GarageYrBlt'].mean()\n",
    "numerical_train['GarageYrBlt'].fillna(avg_garage_year, inplace=True)\n",
    "numerical_test['GarageYrBlt'].fillna(avg_garage_year, inplace=True)\n",
    "# The other values can be 0\n",
    "numerical_train.fillna(0, inplace=True)\n",
    "numerical_test.fillna(0, inplace=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pandas/core/generic.py:6383: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n",
      "/usr/local/lib/python3.8/site-packages/pandas/core/frame.py:5171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating and appending the One Hot Encoders for each categorical column"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "def dummies(df, column):\n",
    "    '''This function accepts a dataframe and a column name. It will get the \n",
    "    one hot encoder for categorical column, then, drop it from the original\n",
    "    dataframe and cancatenate the one hot encoder'''\n",
    "    df1 = pd.get_dummies(df[column])\n",
    "    df = df.drop(columns=[column])\n",
    "    df = pd.concat([df, df1], axis=1)\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "categorical_train, bsmt_col_train = sum_1hots(categorical_train, 'BsmtFinType1', 'BsmtFinType2')\n",
    "categorical_test, bsmt_col_test = sum_1hots(categorical_test, 'BsmtFinType1', 'BsmtFinType2')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "categorical_test['HouseStyle'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1Story    745\n",
       "2Story    427\n",
       "1.5Fin    160\n",
       "SLvl       63\n",
       "SFoyer     46\n",
       "2.5Unf     13\n",
       "1.5Unf      5\n",
       "Name: HouseStyle, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "categorical_train['HouseStyle'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1Story    726\n",
       "2Story    445\n",
       "1.5Fin    154\n",
       "SLvl       65\n",
       "SFoyer     37\n",
       "1.5Unf     14\n",
       "2.5Unf     11\n",
       "2.5Fin      8\n",
       "Name: HouseStyle, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# Using the custom function in the left categorical data columns.\n",
    "for column in categorical_test.columns:\n",
    "    categorical_train = dummies(categorical_train, column)\n",
    "    categorical_test = dummies(categorical_test, column)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "# Appending the sum of one hot encoders created previously\n",
    "for sumhot in [bsmt_col_train, cond_col_train, ext_col_train]:\n",
    "    categorical_train = pd.concat([categorical_train, sumhot], axis=1)\n",
    "\n",
    "for sumhot in [bsmt_col_test, cond_col_test, ext_col_test]:\n",
    "    categorical_test = pd.concat([categorical_test, sumhot], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "# miss_test = [i for i in categorical_train.columns if i not in categorical_test.columns]\n",
    "# for m in miss_test:\n",
    "#     try:\n",
    "#         categorical_train = categorical_train.drop(columns=[m])\n",
    "#     except:\n",
    "#         print('in exp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "# miss_test = [i for i in categorical_train.columns if i not in categorical_test.columns]\n",
    "# miss_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# miss_train = [i for i in categorical_test.columns if i not in categorical_train.columns]\n",
    "# for m in miss_train:\n",
    "#     try:\n",
    "#         categorical_test = categorical_test.drop(columns=[m])\n",
    "#     except:\n",
    "#         print('in exp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "common1 = categorical_train.columns.difference(categorical_test.columns)\n",
    "common2 = categorical_test.columns.difference(categorical_train.columns)\n",
    "categorical_train = categorical_train.drop(columns=common1) \n",
    "categorical_test = categorical_test.drop(columns=common2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "print(common2)\n",
    "print(common1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['1-1/2 STORY PUD - ALL AGES'], dtype='object')\n",
      "Index(['2.5Fin', 'ClyTile', 'Floor', 'Membran', 'Metal', 'Mix', 'NoSeWa',\n",
      "       'OthW', 'Other', 'Roll', 'TenC'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "d1 = categorical_train.columns.difference(categorical_test.columns)\n",
    "d2 = categorical_test.columns.difference(categorical_train.columns)\n",
    "print(d1,d2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index([], dtype='object') Index([], dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "len(categorical_train.columns)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "len(categorical_test.columns)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "miss_train = [i for i in categorical_train.columns if i not in categorical_test.columns]\n",
    "miss_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "dup_test = categorical_test.loc[:,categorical_test.columns.duplicated()].columns\n",
    "dup_train = categorical_train.loc[:,categorical_train.columns.duplicated()].columns\n",
    "dup_test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Grvl', 'Not Aplicable', 'Pave', 'Not Aplicable', 'Not Aplicable', 'Ex',\n",
       "       'Fa', 'Gd', 'TA', 'Stone', 'Ex', 'Fa', 'Gd', 'Not Aplicable', 'TA',\n",
       "       'Fa', 'Gd', 'Not Aplicable', 'Po', 'TA', 'Gd', 'Not Aplicable', 'Ex',\n",
       "       'Fa', 'Gd', 'Po', 'TA', 'Ex', 'Fa', 'Gd', 'Not Aplicable', 'TA', 'Mod',\n",
       "       'Not Aplicable', 'Sev', 'Ex', 'Fa', 'Gd', 'Not Aplicable', 'Po', 'TA',\n",
       "       'Not Aplicable', 'Not Aplicable', 'Fa', 'Gd', 'Not Aplicable', 'Po',\n",
       "       'TA', 'Ex', 'Fa', 'Gd', 'Not Aplicable', 'Po', 'TA', 'N', 'Y', 'Ex',\n",
       "       'Gd', 'Not Aplicable', 'Not Aplicable', 'Not Aplicable', 'Shed',\n",
       "       'Not Aplicable', 'Not Aplicable', 'Unf', 'Normal', 'BrkFace', 'CBlock',\n",
       "       'Stone'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "from collections import defaultdict\n",
    "e = defaultdict(int)\n",
    "f = defaultdict(int)\n",
    "for x in dup_train:\n",
    "    e[x] += 1\n",
    "for x in dup_test:\n",
    "    f[x] += 1\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "e"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Grvl': 1,\n",
       "             'Pave': 1,\n",
       "             'Not Aplicable': 14,\n",
       "             'Ex': 8,\n",
       "             'Fa': 9,\n",
       "             'Gd': 10,\n",
       "             'TA': 8,\n",
       "             'Stone': 2,\n",
       "             'Po': 5,\n",
       "             'Mod': 1,\n",
       "             'Sev': 1,\n",
       "             'N': 1,\n",
       "             'Y': 1,\n",
       "             'Shed': 1,\n",
       "             'Unf': 1,\n",
       "             'Normal': 1,\n",
       "             'BrkFace': 1,\n",
       "             'CBlock': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "f"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Grvl': 1,\n",
       "             'Not Aplicable': 18,\n",
       "             'Pave': 1,\n",
       "             'Ex': 7,\n",
       "             'Fa': 8,\n",
       "             'Gd': 10,\n",
       "             'TA': 8,\n",
       "             'Stone': 2,\n",
       "             'Po': 5,\n",
       "             'Mod': 1,\n",
       "             'Sev': 1,\n",
       "             'N': 1,\n",
       "             'Y': 1,\n",
       "             'Shed': 1,\n",
       "             'Unf': 1,\n",
       "             'Normal': 1,\n",
       "             'BrkFace': 1,\n",
       "             'CBlock': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalizing the numerical data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn import preprocessing\n",
    "#Train set\n",
    "xnumerical_train = numerical_train.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "xnumerical_train_scaled = min_max_scaler.fit_transform(xnumerical_train)\n",
    "\n",
    "# Test set\n",
    "xnumerical_test = numerical_test.values #returns a numpy array\n",
    "xnumerical_test_scaled = min_max_scaler.fit_transform(xnumerical_test)\n",
    "# Filling NaN values with 0\n",
    "xnumerical_test_scaled[np.isnan(xnumerical_test_scaled)] = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting the whole dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "processed_train = np.append(xnumerical_train_scaled, categorical_train.values, axis=1)\n",
    "processed_test = np.append(xnumerical_test_scaled, categorical_test.values, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlations "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# norm_train = pd.DataFrame(data = processed_train, columns=categorical_train.columns.append(numerical_train.columns))\n",
    "# norm_train = pd.concat([norm_train, y], axis=1)\n",
    "# norm_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# corr_matrix = norm_train.corr()\n",
    "# (corr_matrix['SalePrice']\n",
    "# .sort_values(ascending=False)\n",
    "# .where(((corr_matrix['SalePrice'] < -0.05) | (corr_matrix['SalePrice'] > 0.05)), other=np.nan)\n",
    "# .dropna()\n",
    "# )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine Learning Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn import svm\n",
    "\n",
    "regr = svm.SVR()\n",
    "regr.fit(processed_train, y.values)\n",
    "predictions_train = regr.predict(processed_train)\n",
    "predictions_svm = regr.predict(processed_test)\n",
    "predictions_svm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.mean(predictions_train / y.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import csv\n",
    "j = 1461\n",
    "with open('predictions.csv', 'w') as p:\n",
    "    writer = csv.writer(p)\n",
    "    writer.writerow(['Id','SalePrice'])\n",
    "    for pred in predictions:\n",
    "        writer.writerow([j,pred])\n",
    "        j += 1\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd = SGDRegressor(max_iter=5000, learning_rate='adaptive')\n",
    "sgd.fit(processed_train, y.values)\n",
    "predictions_sgd_train = sgd.predict(processed_train)\n",
    "# predictions_sgd = sgd.predict(processed_test)\n",
    "# predictions_sgd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.max(predictions_sgd_train / y.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import csv\n",
    "j = 1461\n",
    "with open('predictions2.csv', 'w') as p:\n",
    "    writer = csv.writer(p)\n",
    "    writer.writerow(['Id','SalePrice'])\n",
    "    for pred in predictions_sgd:\n",
    "        writer.writerow([j,pred])\n",
    "        j += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categorical_columns = list(house_data_train.dtypes[house_data_train.dtypes == np.object])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}