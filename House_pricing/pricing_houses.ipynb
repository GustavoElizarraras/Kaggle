{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows = 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "source": [
    "# Creating the datasets\n",
    "house_data_train = pd.read_csv(\"train.csv\")\n",
    "house_data_test = pd.read_csv(\"test.csv\")\n",
    "# Target prices:\n",
    "y = house_data_train['SalePrice']\n",
    "house_data_train = house_data_train.drop(columns=['SalePrice'])\n",
    "house_data_train.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 912.6+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "source": [
    "# Values and meanings from the first column, MSSubClass\n",
    "MSSubClass_dict = { \n",
    "        20:\t'1-STORY 1946 & NEWER ALL STYLES', \n",
    "        30:\t'1-STORY 1945 & OLDER', \n",
    "        40:\t'1-STORY W/FINISHED ATTIC ALL AGES',\n",
    "        45:\t'1-1/2 STORY - UNFINISHED ALL AGES', \n",
    "        50:\t'1-1/2 STORY FINISHED ALL AGES', \n",
    "        60:\t'2-STORY 1946 & NEWER', \n",
    "        70:\t'2-STORY 1945 & OLDER', \n",
    "        75:\t'2-1/2 STORY ALL AGES', \n",
    "        80:\t'SPLIT OR MULTI-LEVEL', \n",
    "        85:\t'SPLIT FOYER', \n",
    "        90:\t'DUPLEX - ALL STYLES AND AGES', \n",
    "       120:\t'1-STORY PUD (Planned Unit Development) - 1946 & NEWER', \n",
    "       150:\t'1-1/2 STORY PUD - ALL AGES', \n",
    "       160:\t'2-STORY PUD - 1946 & NEWER', \n",
    "       180:\t'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER', \n",
    "       190:\t'2 FAMILY CONVERSION - ALL STYLES AND AGES'}\n",
    "\n",
    "# Replacing numbers with column names\n",
    "house_data_train['MSSubClass'].replace(MSSubClass_dict, inplace=True)\n",
    "house_data_test['MSSubClass'].replace(MSSubClass_dict, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "categorical_columns = list(house_data_train.dtypes[house_data_train.dtypes == np.object].index)\n",
    "numerical_columns = list(house_data_train.dtypes[house_data_train.dtypes != np.object].index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "source": [
    "# Numerical and categorical dataframes\n",
    "numerical_train = house_data_train[numerical_columns]\n",
    "numerical_test = house_data_test[numerical_columns]\n",
    "categorical_train = house_data_train[categorical_columns]\n",
    "categorical_test = house_data_test[categorical_columns]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "# Meanings of the Condition1 and Condition2 column values\n",
    "cond = {\n",
    "    'Artery':\t'Adjacent to arterial street',\n",
    "    'Feedr':\t'Adjacent to feeder street',\t\n",
    "    'Norm':\t'Normal',\t\n",
    "    'RRNn':\t'Within 200 of North-South Railroad',\n",
    "    'RRAn':\t'Adjacent to North-South Railroad',\n",
    "    'PosN':\t'Near positive off-site feature--park, greenbelt, etc.',\n",
    "    'PosA':\t'Adjacent to postive off-site feature',\n",
    "    'RRNe':\t'Within 200 of East-West Railroad',\n",
    "    'RRAe':\t'Adjacent to East-West Railroad'\n",
    "}\n",
    "# Getting the full name of the conditions\n",
    "categorical_train['Condition1'].replace(cond, inplace=True)\n",
    "categorical_train['Condition2'].replace(cond, inplace=True)\n",
    "categorical_test['Condition1'].replace(cond, inplace=True)\n",
    "categorical_test['Condition2'].replace(cond, inplace=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pandas/core/generic.py:6610: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "source": [
    "def sum_1hots(df, column1, column2):\n",
    "    '''This function is for getting only one hot encoder for repeated \n",
    "    conditions in some columns in the dataset '''\n",
    "    c1 = pd.get_dummies(df[column1])\n",
    "    c2 = pd.get_dummies(df[column2])\n",
    "    # Sum both one hot encoders. Exploring this data, I found some 2's, that makes \n",
    "    # no sense, so, I replaced them with 1's\n",
    "    c1c2 = c1.add(c2, fill_value=0).replace(2,1)\n",
    "    df = df.drop(columns=[column1, column2])\n",
    "    return df, c1c2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "source": [
    "categorical_train, cond_col_train = sum_1hots(categorical_train, 'Condition1', 'Condition2')\n",
    "categorical_train, ext_col_train = sum_1hots(categorical_train, 'Exterior1st', 'Exterior2nd')\n",
    "categorical_test, cond_col_test = sum_1hots(categorical_test, 'Condition1', 'Condition2')\n",
    "categorical_test, ext_col_test = sum_1hots(categorical_test, 'Exterior1st', 'Exterior2nd')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handling zero values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "source": [
    "categorical_train.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 40 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   MSSubClass     1460 non-null   object\n",
      " 1   MSZoning       1460 non-null   object\n",
      " 2   Street         1460 non-null   object\n",
      " 3   Alley          91 non-null     object\n",
      " 4   LotShape       1460 non-null   object\n",
      " 5   LandContour    1460 non-null   object\n",
      " 6   Utilities      1460 non-null   object\n",
      " 7   LotConfig      1460 non-null   object\n",
      " 8   LandSlope      1460 non-null   object\n",
      " 9   Neighborhood   1460 non-null   object\n",
      " 10  BldgType       1460 non-null   object\n",
      " 11  HouseStyle     1460 non-null   object\n",
      " 12  RoofStyle      1460 non-null   object\n",
      " 13  RoofMatl       1460 non-null   object\n",
      " 14  MasVnrType     1452 non-null   object\n",
      " 15  ExterQual      1460 non-null   object\n",
      " 16  ExterCond      1460 non-null   object\n",
      " 17  Foundation     1460 non-null   object\n",
      " 18  BsmtQual       1423 non-null   object\n",
      " 19  BsmtCond       1423 non-null   object\n",
      " 20  BsmtExposure   1422 non-null   object\n",
      " 21  BsmtFinType1   1423 non-null   object\n",
      " 22  BsmtFinType2   1422 non-null   object\n",
      " 23  Heating        1460 non-null   object\n",
      " 24  HeatingQC      1460 non-null   object\n",
      " 25  CentralAir     1460 non-null   object\n",
      " 26  Electrical     1459 non-null   object\n",
      " 27  KitchenQual    1460 non-null   object\n",
      " 28  Functional     1460 non-null   object\n",
      " 29  FireplaceQu    770 non-null    object\n",
      " 30  GarageType     1379 non-null   object\n",
      " 31  GarageFinish   1379 non-null   object\n",
      " 32  GarageQual     1379 non-null   object\n",
      " 33  GarageCond     1379 non-null   object\n",
      " 34  PavedDrive     1460 non-null   object\n",
      " 35  PoolQC         7 non-null      object\n",
      " 36  Fence          281 non-null    object\n",
      " 37  MiscFeature    54 non-null     object\n",
      " 38  SaleType       1460 non-null   object\n",
      " 39  SaleCondition  1460 non-null   object\n",
      "dtypes: object(40)\n",
      "memory usage: 456.4+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "source": [
    "# Replacing with a string the nan values. While exploring what kind of nan values we have in the data, \n",
    "# is ok to fill with a Not Aplicable condition. (no basement, no pool, etc)\n",
    "categorical_train.fillna('Not Aplicable', inplace=True)\n",
    "categorical_test.fillna('Not Aplicable', inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "source": [
    "# With the numerical columns, we only have one that is special, the \n",
    "# year when the garage was built, we fill with the average year\n",
    "avg_garage_year = numerical_train['GarageYrBlt'].mean()\n",
    "numerical_train['GarageYrBlt'].fillna(avg_garage_year, inplace=True)\n",
    "numerical_test['GarageYrBlt'].fillna(avg_garage_year, inplace=True)\n",
    "# The other values can be 0\n",
    "numerical_train.fillna(0, inplace=True)\n",
    "numerical_test.fillna(0, inplace=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pandas/core/generic.py:6383: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n",
      "/usr/local/lib/python3.8/site-packages/pandas/core/frame.py:5171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating and appending the One Hot Encoders for each categorical column"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "def drop_concat(df, one_hot, column):\n",
    "    '''This function accepts a dataframe and a column name. It will get the \n",
    "    one hot encoder for categorical column, then, drop it from the original\n",
    "    dataframe and cancatenate the one hot encoder'''\n",
    "    df = df.drop(columns=[column])\n",
    "    df = pd.concat([df, one_hot], axis=1)\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "def complete_categorical(df1, df2):\n",
    "    '''Sometimes there are values not present in the test and train set, and\n",
    "    in the one hot encoder this result in different number of columns. In \n",
    "    order to have control over it, this function completes those columns with 0'''\n",
    "    cdf1 = df1.columns\n",
    "    cdf2 = df2.columns\n",
    "    for not_in_df2 in cdf1.difference(cdf2):\n",
    "        df2[not_in_df2] = 0\n",
    "    for not_in_df1 in cdf2.difference(cdf1):\n",
    "        df1[not_in_df1] = 0\n",
    "    df1 = df1.reindex(sorted(df1.columns), axis=1)\n",
    "    df2 = df2.reindex(sorted(df2.columns), axis=1)\n",
    "    return df1, df2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "categorical_train, bsmt_col_train = sum_1hots(categorical_train, 'BsmtFinType1', 'BsmtFinType2')\n",
    "categorical_test, bsmt_col_test = sum_1hots(categorical_test, 'BsmtFinType1', 'BsmtFinType2')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "# Using the custom functions to get completes categorical train and test set\n",
    "for column in categorical_test.columns:\n",
    "    OH_train = pd.get_dummies(categorical_train[column])\n",
    "    OH_test = pd.get_dummies(categorical_test[column])\n",
    "    OH_train, OH_test = complete_categorical(OH_train, OH_test)\n",
    "    categorical_train = drop_concat(categorical_train, OH_train, column)\n",
    "    categorical_test = drop_concat(categorical_test, OH_test, column)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "# Appending the sum of one hot encoders created previously and completing missing columns\n",
    "hot_sums_train = [bsmt_col_train, cond_col_train, ext_col_train]\n",
    "hot_sums_test = [bsmt_col_test, cond_col_test, ext_col_test]\n",
    "for i in range(len(hot_sums_train)):\n",
    "    complete_hot_sums_train, complete_hot_sums_test = complete_categorical(hot_sums_train[i], hot_sums_test[i])\n",
    "    categorical_train = pd.concat([categorical_train, complete_hot_sums_train], axis=1)\n",
    "    categorical_test = pd.concat([categorical_test, complete_hot_sums_test], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "len(categorical_train.columns)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "metadata": {},
     "execution_count": 206
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "source": [
    "len(categorical_test.columns)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalizing the numerical data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "source": [
    "from sklearn import preprocessing\n",
    "#Train set\n",
    "xnumerical_train = numerical_train.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "xnumerical_train_scaled = min_max_scaler.fit_transform(xnumerical_train)\n",
    "\n",
    "# Test set\n",
    "xnumerical_test = numerical_test.values #returns a numpy array\n",
    "xnumerical_test_scaled = min_max_scaler.fit_transform(xnumerical_test)\n",
    "# Filling NaN values with 0\n",
    "xnumerical_test_scaled[np.isnan(xnumerical_test_scaled)] = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting the whole dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "source": [
    "processed_train = np.append(xnumerical_train_scaled, categorical_train.values, axis=1)\n",
    "processed_test = np.append(xnumerical_test_scaled, categorical_test.values, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlations "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "source": [
    "# norm_train = pd.DataFrame(data = processed_train, columns=categorical_train.columns.append(numerical_train.columns))\n",
    "# norm_train = pd.concat([norm_train, y], axis=1)\n",
    "# norm_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "source": [
    "# corr_matrix = norm_train.corr()\n",
    "# (corr_matrix['SalePrice']\n",
    "# .sort_values(ascending=False)\n",
    "# .where(((corr_matrix['SalePrice'] < -0.05) | (corr_matrix['SalePrice'] > 0.05)), other=np.nan)\n",
    "# .dropna()\n",
    "# )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine Learning Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "source": [
    "from sklearn import svm\n",
    "\n",
    "regr = svm.SVR()\n",
    "regr.fit(processed_train, y.values)\n",
    "predictions_train = regr.predict(processed_train)\n",
    "predictions_svm = regr.predict(processed_test)\n",
    "predictions_svm"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([162963.56851397, 163006.75946828, 163086.07895499, ...,\n",
       "       162994.69052088, 163010.38607215, 163087.70421863])"
      ]
     },
     "metadata": {},
     "execution_count": 212
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "source": [
    "np.mean(predictions_train / y.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0586732478812362"
      ]
     },
     "metadata": {},
     "execution_count": 213
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "source": [
    "import csv\n",
    "j = 1461\n",
    "with open('predictions.csv', 'w') as p:\n",
    "    writer = csv.writer(p)\n",
    "    writer.writerow(['Id','SalePrice'])\n",
    "    for pred in predictions:\n",
    "        writer.writerow([j,pred])\n",
    "        j += 1\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_473/1563504537.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd = SGDRegressor(max_iter=5000, learning_rate='adaptive')\n",
    "sgd.fit(processed_train, y.values)\n",
    "predictions_sgd_train = sgd.predict(processed_train)\n",
    "# predictions_sgd = sgd.predict(processed_test)\n",
    "# predictions_sgd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.max(predictions_sgd_train / y.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import csv\n",
    "j = 1461\n",
    "with open('predictions2.csv', 'w') as p:\n",
    "    writer = csv.writer(p)\n",
    "    writer.writerow(['Id','SalePrice'])\n",
    "    for pred in predictions_sgd:\n",
    "        writer.writerow([j,pred])\n",
    "        j += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categorical_columns = list(house_data_train.dtypes[house_data_train.dtypes == np.object])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}